{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from beakerx import *\n",
    "from beakerx.object import beakerx\n",
    "import numpy as np\n",
    "from multiprocess import Pool, cpu_count\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Code/')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_apply(df, group_list, f, num_cores, print_every_n=1000):\n",
    "    \"\"\"\n",
    "    A lightweight version of apply using the multiprocess library\n",
    "\n",
    "    :param df: the pandas dataframe that needs to be grouped\n",
    "    :param group_list: a list of variable names to group by\n",
    "    :param f: the function that operates on dataframes to apply to each grouped dataframe\n",
    "    :param num_cores: the number of cores to use\n",
    "    :param print_every_n: a message will be printed every print_every_n groups processed by\n",
    "    each core. If print_every_n = None, then no messages will be printed\n",
    "\n",
    "    :return: a dataframe that has had the apply function done on it\n",
    "\n",
    "    Usage:\n",
    "\n",
    "    NUM_GROUPS = 10000\n",
    "    SIZE_OF_GROUP = 4\n",
    "    N = NUM_GROUPS * SIZE_OF_GROUP\n",
    "    df_one_group = pd.DataFrame({'g1': np.random.randint(low = 1, high = NUM_GROUPS, size = N),\n",
    "                                'data': np.random.random(N) - 0.5})\n",
    "\n",
    "    def slow_max(d):\n",
    "        ret = d.sort_values(['data'], ascending = False)\n",
    "        return ret.iloc[0, :]\n",
    "\n",
    "    par = parallel_apply(df_one_group, ['g1'], slow_max, 4).head()\n",
    "    serial = df_one_group.groupby(['g1']).apply(slow_max).head()\n",
    "    assert(np.all(par['data'].values == serial['data'].values))\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cut up the dataframes into a list\n",
    "    num_cores = int(num_cores)\n",
    "    group_numbers = df.groupby(by=group_list).ngroup()\n",
    "    group_cuts = group_numbers.quantile(np.linspace(0, 1, num = num_cores + 1), interpolation='nearest').values\n",
    "    df['_Group'] = group_numbers\n",
    "\n",
    "    if print_every_n != None:\n",
    "        print('Total of ' + str(group_cuts[-1]) + ' groups')\n",
    "\n",
    "    cuts = []\n",
    "    for ind in range(num_cores - 1):\n",
    "        cuts.append(\n",
    "            df.loc[(group_numbers >= group_cuts[ind]) & (group_numbers < group_cuts[ind + 1])].groupby(group_list))\n",
    "    cuts.append(df.loc[(group_numbers >= group_cuts[num_cores - 1]) & (group_numbers <= group_cuts[num_cores])].groupby(\n",
    "        group_list))\n",
    "\n",
    "    # Define functions to be passed to parallel process\n",
    "    def verbose_function(dataframe):\n",
    "        curr = dataframe['_Group'].values[0]\n",
    "        if curr % print_every_n == 0:\n",
    "            print('Group: ' + str(curr))\n",
    "        return f(dataframe)\n",
    "\n",
    "    def verbose_func_to_apply(group_by_object):\n",
    "        return group_by_object.apply(verbose_function)\n",
    "\n",
    "#     def silent_func(dataframe):\n",
    "#         return f(dataframe.drop(['_Group'], axis = 1))\n",
    "#         #return f(dataframe.loc[:, dataframe.columns != '_Group'])\n",
    "\n",
    "    def silent_func_to_apply(group_by_object):\n",
    "        return group_by_object.apply(f)\n",
    "#         return group_by_object.apply(silent_func)\n",
    "\n",
    "    with Pool(num_cores) as p:\n",
    "        if print_every_n != None:\n",
    "            parallel_results = p.map(verbose_func_to_apply, cuts)\n",
    "        else:\n",
    "            parallel_results = p.map(silent_func_to_apply, cuts)\n",
    "\n",
    "    ret = pd.concat(parallel_results)\n",
    "    df.safe_drop(['_Group'], inplace = True)\n",
    "    \n",
    "    if len(ret.shape) > 1: # The case when returning a series\n",
    "        ret.safe_drop(['_Group'], inplace = True)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 5000\n",
      "Group: 10000\n",
      "Group: 15000\n",
      "Group: 1000\n",
      "Group: 6000\n",
      "Group: 11000\n",
      "Group: 16000\n",
      "Group: 2000\n",
      "Group: 7000\n",
      "Group: 12000\n",
      "Group: 17000\n",
      "Group: 3000\n",
      "Group: 8000\n",
      "Group: 13000\n",
      "Group: 18000\n",
      "Group: 4000\n",
      "Group: 9000\n",
      "Group: 14000\n",
      "Group: 19000\n"
     ]
    }
   ],
   "source": [
    "NUM_GROUPS = 20000\n",
    "SIZE_OF_GROUP = 4\n",
    "N = NUM_GROUPS * SIZE_OF_GROUP\n",
    "df_one_group = pd.DataFrame({'g1': np.random.randint(low = 1, high = NUM_GROUPS, size = N),\n",
    "                            'data': np.random.random(N) - 0.5})\n",
    "\n",
    "def slow_max(d):\n",
    "    ret = d.sort_values(['data'], ascending = False)\n",
    "    return ret.iloc[0, :]\n",
    "\n",
    "par = parallel_apply(df_one_group, ['g1'], slow_max, 4).head()\n",
    "serial = df_one_group.groupby(['g1']).apply(slow_max).head()\n",
    "assert(np.all(par['data'].values == serial['data'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_group = df_one_group.safe_index(['g1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538af0b58712479a949414eb4575a179",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_one_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "Total of 19648 groups\n",
      "Group: 0\n",
      "Group: 0\n",
      "Group: 10000\n",
      "Group: 5000\n",
      "Group: 15000\n",
      "6 s ± 192 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit parallel_apply(df_one_group, ['g1'], slow_max, 2, print_every_n = 5000).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14 s ± 49.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit parallel_apply(df_one_group, ['g1'], slow_max, 2, print_every_n = None).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 s ± 464 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df_one_group.groupby(['g1']).apply(slow_max).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f parallel_apply parallel_apply(df_one_group, ['g1'], slow_max, 4, print_every_n = None).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%mprun -f parallel_apply parallel_apply(df_one_group, ['g1'], slow_max, 4, print_every_n = None).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
